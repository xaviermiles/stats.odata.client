% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fct_odata_get.R
\name{parallel_get}
\alias{parallel_get}
\title{Parallelised version of basic_get, for requesting larger amounts of data.}
\usage{
parallel_get(
  endpoint,
  entity = "",
  query = "",
  timeout = 60,
  splitting_col = "ResourceID",
  max_cores = 4,
  rows_per_query = 20000
)
}
\arguments{
\item{endpoint}{API endpoint. Required.}

\item{entity}{Data entity.}

\item{query}{Query URL character (not URL-encoded).}

\item{timeout}{Timeout for the GET request(s), in seconds.}

\item{splitting_col}{The column on which to split the overall request into
bite-size portions.}

\item{max_cores}{Maximum number of cores. This will be overruled if there is
less cores available.}

\item{rows_per_query}{The approx. number of rows per individual request.
This can be used to tune performance.}
}
\description{
This uses multiples cores to make concurrent API requests, and
then merges the individual results. There is some upfront work required to
determine the series of smaller requests, so this function shouldn't be used
for "small" requests.

FIXME: currently ignores query and timeout args
}
